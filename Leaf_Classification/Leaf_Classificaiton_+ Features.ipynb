{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68bd73e-aa17-4186-be8f-cf555d922ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd3ee81-2c6d-44fa-aa7a-17bdc2079055",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48dda58f-38ff-4e27-bfef-47323857ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def process(data, image_path):\n",
    "    data['Id'] = data['id'].astype(str) + '.jpg'\n",
    "    \n",
    "    data['image_paths'] = data['Id'].apply(lambda x: os.path.join(image_path, x))\n",
    "    data = data[['image_paths'] + [col for col in data.columns if col != 'image_paths']]\n",
    "    \n",
    "    img = cv2.imread(data['image_paths'][0])\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert from BGR to RGB\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "    return data\n",
    "\n",
    "def preprocess(data):\n",
    "    x=[]\n",
    "    for img in data['image_paths']:\n",
    "        img = cv2.imread(img)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #since our images are already black and white.\n",
    "        img = cv2.resize(img, (164, 164))\n",
    "        img=img/255.0    \n",
    "        x.append(img)\n",
    "    image_array =np.array(x)\n",
    "    return image_array\n",
    "\n",
    "def features_extraction_test(data):\n",
    "    features = data.drop(columns = ['image_paths','Id','id'])\n",
    "    features_data = features.to_numpy() \n",
    "    return features_data\n",
    "\n",
    "def features_extraction_train(data):\n",
    "    features = data.drop(columns = ['image_paths','Id','id','species'])\n",
    "    features_data = features.to_numpy() \n",
    "    return features_data\n",
    "\n",
    "def target_extraction_train(data):\n",
    "    target = data['species']\n",
    "    y = label_encoder.fit_transform(target)\n",
    "    target = pd.DataFrame(y) #sparse categorical crossentropy as the loss fucntion because our labels are integers.\n",
    "    \n",
    "    target.columns = ['label']\n",
    "    print(f'Class amount to set the last layer of the model is: {target.label.nunique()}') #amount of classes\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa01ddb-03d4-438f-9e0c-3e3f23092dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = process(test_df,'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be9e490-a3f1-4aa4-9df7-5a268b6459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a755a04-1dcd-4f72-a0bb-b092587e999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = features_extraction_test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca031b1c-361a-4c2f-a599-8999519c1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc4f0fe-8b71-4925-8e48-f9ef468e778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = process(df,'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096c92be-fb54-422c-bc47-69c643a9512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b112f0b-0d6f-447c-b736-e0d8421b35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_extraction_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a334d7d-ce4f-40f5-a5f6-bae68188a348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class amount to set the last layer of the model is: 99\n"
     ]
    }
   ],
   "source": [
    "target_train = target_extraction_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00eaecd-df71-4809-b85a-ce2d06ccd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "image_height, image_width, channel = 164, 164, 3\n",
    "\n",
    "# CNN Part for Image Feature Extraction (CONVOLUTIONAL NEURAL NETWORK PART)\n",
    "image_input = Input(shape=(image_height, image_width, channel))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)  # Latent Space (Bottleneck)\n",
    "\n",
    "# Numerical Data Part for CSV Features (DEEP NEURAL NETWORK PART)\n",
    "csv_input = Input(shape=(192,))  # features.shape\n",
    "y = Dense(128, activation='relu')(csv_input)\n",
    "#y = Dense(64, activation='relu')(y)\n",
    "y = Dense(32, activation='relu')(y)\n",
    "\n",
    "# Concatenate Latent Space from CNN with CSV Numerical Features\n",
    "combined = Concatenate()([x, y])\n",
    "\n",
    "# Final Fully Connected Layers for Classification\n",
    "z = Dense(128, activation='relu')(combined)\n",
    "z = Dense(99, activation='softmax')(z)\n",
    "\n",
    "# Define and Compile the Model\n",
    "model = Model(inputs=[image_input, csv_input], outputs=z)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "846233b7-cdf0-497f-871d-6e3bfa2c257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_path = \"best_model.keras\"  # File path to save the model\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "#    save_weights_only=True,  # Save only the weights\n",
    "    monitor='loss',          # Monitor training loss\n",
    "    save_best_only=True,     # Save only the best model\n",
    "    mode='min',              # Save the model when the monitored quantity is minimized\n",
    "    verbose=1               # Print messages when saving the model\n",
    ")\n",
    "\n",
    "#model.load_weights(checkpoint_path)\n",
    "#mode: Defines whether to minimize or maximize the monitored metric. Use 'min' for loss and 'max' for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0fda69f-21be-4b12-8935-5761411d228e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.0386 - loss: 4.5296\n",
      "Epoch 1: loss improved from inf to 4.27215, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 191ms/step - accuracy: 0.0393 - loss: 4.5256\n",
      "Epoch 2/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.4675 - loss: 2.2579\n",
      "Epoch 2: loss improved from 4.27215 to 2.04201, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 183ms/step - accuracy: 0.4680 - loss: 2.2545\n",
      "Epoch 3/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7565 - loss: 0.9076\n",
      "Epoch 3: loss improved from 2.04201 to 0.92981, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 209ms/step - accuracy: 0.7563 - loss: 0.9080\n",
      "Epoch 4/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8715 - loss: 0.4477\n",
      "Epoch 4: loss improved from 0.92981 to 0.51720, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 186ms/step - accuracy: 0.8711 - loss: 0.4488\n",
      "Epoch 5/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9444 - loss: 0.1753\n",
      "Epoch 5: loss improved from 0.51720 to 0.18331, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - accuracy: 0.9444 - loss: 0.1755\n",
      "Epoch 6/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9756 - loss: 0.0850\n",
      "Epoch 6: loss improved from 0.18331 to 0.11298, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 205ms/step - accuracy: 0.9755 - loss: 0.0854\n",
      "Epoch 7/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9726 - loss: 0.1027\n",
      "Epoch 7: loss improved from 0.11298 to 0.10460, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 210ms/step - accuracy: 0.9725 - loss: 0.1027\n",
      "Epoch 8/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9880 - loss: 0.0538\n",
      "Epoch 8: loss improved from 0.10460 to 0.03694, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 221ms/step - accuracy: 0.9880 - loss: 0.0536\n",
      "Epoch 9/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9975 - loss: 0.0164\n",
      "Epoch 9: loss improved from 0.03694 to 0.01797, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step - accuracy: 0.9975 - loss: 0.0164\n",
      "Epoch 10/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 10: loss improved from 0.01797 to 0.00426, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 11/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 11: loss improved from 0.00426 to 0.00283, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 12/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9962 - loss: 0.0152\n",
      "Epoch 12: loss did not improve from 0.00283\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.9962 - loss: 0.0152\n",
      "Epoch 13/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9990 - loss: 0.0048\n",
      "Epoch 13: loss did not improve from 0.00283\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 206ms/step - accuracy: 0.9990 - loss: 0.0049\n",
      "Epoch 14/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9982 - loss: 0.0147\n",
      "Epoch 14: loss did not improve from 0.00283\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 193ms/step - accuracy: 0.9982 - loss: 0.0146\n",
      "Epoch 15/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 5.1405e-04\n",
      "Epoch 15: loss improved from 0.00283 to 0.00054, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 5.1440e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 2.4823e-04\n",
      "Epoch 16: loss improved from 0.00054 to 0.00023, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 2.4792e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 1.4030e-04\n",
      "Epoch 17: loss improved from 0.00023 to 0.00014, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 1.4026e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 1.1031e-04\n",
      "Epoch 18: loss improved from 0.00014 to 0.00011, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1026e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 9.3812e-05\n",
      "Epoch 19: loss improved from 0.00011 to 0.00009, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 9.3686e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 7.1687e-05\n",
      "Epoch 20: loss improved from 0.00009 to 0.00007, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 7.1692e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 5.9826e-05\n",
      "Epoch 21: loss improved from 0.00007 to 0.00006, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 5.9843e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 5.0886e-05\n",
      "Epoch 22: loss improved from 0.00006 to 0.00005, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 5.0921e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 4.6493e-05\n",
      "Epoch 23: loss improved from 0.00005 to 0.00005, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 4.6487e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 4.2717e-05\n",
      "Epoch 24: loss improved from 0.00005 to 0.00004, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 4.2688e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 4.2187e-05\n",
      "Epoch 25: loss improved from 0.00004 to 0.00004, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 4.2088e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 3.1135e-05\n",
      "Epoch 26: loss improved from 0.00004 to 0.00003, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 3.1153e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 2.7377e-05\n",
      "Epoch 27: loss improved from 0.00003 to 0.00003, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 2.7402e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 2.4474e-05\n",
      "Epoch 28: loss improved from 0.00003 to 0.00003, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 2.4502e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 2.4315e-05\n",
      "Epoch 29: loss improved from 0.00003 to 0.00002, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 2.4306e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 1.8425e-05\n",
      "Epoch 30: loss improved from 0.00002 to 0.00002, saving model to best_model.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 1.8478e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_images, features_train], target_train, epochs=30, batch_size=16, callbacks=[model_checkpoint_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f72c508d-b83d-4fc1-812e-6c023cd26bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is: 1.8478e-05 which is 0.0000184\n"
     ]
    }
   ],
   "source": [
    "print('Loss is: 1.8478e-05 which is 0.0000184')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34247e0a-ccfe-4bda-962b-a35305a040d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_model_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b661ec7-8ee2-4121-8085-a91c608d6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#loaded_model = load_model('my_model_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94a604a5-90a8-49f1-927d-7d17a51e84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = loaded_model.predict([test_images, features_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "954b7883-9b08-49f2-969e-134ae41ce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "my_model = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac3054d-103c-4808-b782-1b8e8685f194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = my_model.predict([test_images, features_test])\n",
    "#predictions = np.clip(predictions, 1e-15, 1 - 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78670869-880f-4278-bbd4-ee710b1f0e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 99)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape #(num_test_images, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cece4e-9772-4ee3-bb5d-4bb20c8d00a2",
   "metadata": {},
   "source": [
    "### Prepare Candidate Species Names\n",
    "    We used label encoder to encode the target categories with number, we can reverse that encoding to get the species names back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b6b0303-4f6a-41bd-975a-64a0df1133a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8024e32-c537-45a0-9fd8-c4f2fe5b3b0c",
   "metadata": {},
   "source": [
    "## Forming Submission Data Frame,\n",
    "    -> image_ids: Extracted from your test dataset, representing the unique identifier for each image (e.g., file name).\n",
    "    -> species_names: Using the LabelEncoder to get the names of all species from the integer class indices. We inverse transformed the names of our ids back to the categorical (string) value.\n",
    "        For each image:\n",
    "        We fetch the image ID.\n",
    "        We append the predicted probabilities for all species to the row.\n",
    "    -> submission_df: A Pandas DataFrame containing all image IDs, species names, and their associated probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854c7ed4-0433-4203-902d-13c64c52712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image IDs from your test dataframe\n",
    "image_ids = test_df['id'].values \n",
    "\n",
    "# Get species names back in original order using LabelEncoder\n",
    "species_names = label_encoder.inverse_transform(np.arange(99))\n",
    "\n",
    "\n",
    "submission_data = []\n",
    "\n",
    "# Loop through each image's predictions\n",
    "for i, img_id in enumerate(image_ids):\n",
    "    # Get the probabilities for the current image\n",
    "    img_probs = predictions[i]\n",
    "    \n",
    "    # Prepare a dictionary for each row, with image ID and probabilities for each species\n",
    "    row = {\n",
    "        'id': img_id\n",
    "    }\n",
    "    \n",
    "    # Add all species probabilities to the row (species_names[j]: img_probs[j] for each j)\n",
    "    for j, species_name in enumerate(species_names):\n",
    "        row[species_name] = img_probs[j]\n",
    "    \n",
    "    # Append the row to the submission data list\n",
    "    submission_data.append(row)\n",
    "\n",
    "# Convert the submission data into a DataFrame\n",
    "submission_df = pd.DataFrame(submission_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a5bc238-f948-457f-8858-18c6bc1f945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>Alnus_Cordata</th>\n",
       "      <th>Alnus_Maximowiczii</th>\n",
       "      <th>Alnus_Rubra</th>\n",
       "      <th>Alnus_Sieboldiana</th>\n",
       "      <th>Alnus_Viridis</th>\n",
       "      <th>Arundinaria_Simonii</th>\n",
       "      <th>Betula_Austrosinensis</th>\n",
       "      <th>Betula_Pendula</th>\n",
       "      <th>Callicarpa_Bodinieri</th>\n",
       "      <th>Castanea_Sativa</th>\n",
       "      <th>Celtis_Koraiensis</th>\n",
       "      <th>Cercis_Siliquastrum</th>\n",
       "      <th>Cornus_Chinensis</th>\n",
       "      <th>Cornus_Controversa</th>\n",
       "      <th>Cornus_Macrophylla</th>\n",
       "      <th>Cotinus_Coggygria</th>\n",
       "      <th>Crataegus_Monogyna</th>\n",
       "      <th>Cytisus_Battandieri</th>\n",
       "      <th>Eucalyptus_Glaucescens</th>\n",
       "      <th>Eucalyptus_Neglecta</th>\n",
       "      <th>Eucalyptus_Urnigera</th>\n",
       "      <th>Fagus_Sylvatica</th>\n",
       "      <th>Ginkgo_Biloba</th>\n",
       "      <th>Ilex_Aquifolium</th>\n",
       "      <th>Ilex_Cornuta</th>\n",
       "      <th>Liquidambar_Styraciflua</th>\n",
       "      <th>Liriodendron_Tulipifera</th>\n",
       "      <th>Lithocarpus_Cleistocarpus</th>\n",
       "      <th>Lithocarpus_Edulis</th>\n",
       "      <th>Magnolia_Heptapeta</th>\n",
       "      <th>Magnolia_Salicifolia</th>\n",
       "      <th>Morus_Nigra</th>\n",
       "      <th>Olea_Europaea</th>\n",
       "      <th>Phildelphus</th>\n",
       "      <th>Populus_Adenopoda</th>\n",
       "      <th>Populus_Grandidentata</th>\n",
       "      <th>Populus_Nigra</th>\n",
       "      <th>Prunus_Avium</th>\n",
       "      <th>Prunus_X_Shmittii</th>\n",
       "      <th>Pterocarya_Stenoptera</th>\n",
       "      <th>Quercus_Afares</th>\n",
       "      <th>Quercus_Agrifolia</th>\n",
       "      <th>Quercus_Alnifolia</th>\n",
       "      <th>Quercus_Brantii</th>\n",
       "      <th>Quercus_Canariensis</th>\n",
       "      <th>Quercus_Castaneifolia</th>\n",
       "      <th>Quercus_Cerris</th>\n",
       "      <th>Quercus_Chrysolepis</th>\n",
       "      <th>Quercus_Coccifera</th>\n",
       "      <th>Quercus_Coccinea</th>\n",
       "      <th>Quercus_Crassifolia</th>\n",
       "      <th>Quercus_Crassipes</th>\n",
       "      <th>Quercus_Dolicholepis</th>\n",
       "      <th>Quercus_Ellipsoidalis</th>\n",
       "      <th>Quercus_Greggii</th>\n",
       "      <th>Quercus_Hartwissiana</th>\n",
       "      <th>Quercus_Ilex</th>\n",
       "      <th>Quercus_Imbricaria</th>\n",
       "      <th>Quercus_Infectoria_sub</th>\n",
       "      <th>Quercus_Kewensis</th>\n",
       "      <th>Quercus_Nigra</th>\n",
       "      <th>Quercus_Palustris</th>\n",
       "      <th>Quercus_Phellos</th>\n",
       "      <th>Quercus_Phillyraeoides</th>\n",
       "      <th>Quercus_Pontica</th>\n",
       "      <th>Quercus_Pubescens</th>\n",
       "      <th>Quercus_Pyrenaica</th>\n",
       "      <th>Quercus_Rhysophylla</th>\n",
       "      <th>Quercus_Rubra</th>\n",
       "      <th>Quercus_Semecarpifolia</th>\n",
       "      <th>Quercus_Shumardii</th>\n",
       "      <th>Quercus_Suber</th>\n",
       "      <th>Quercus_Texana</th>\n",
       "      <th>Quercus_Trojana</th>\n",
       "      <th>Quercus_Variabilis</th>\n",
       "      <th>Quercus_Vulcanica</th>\n",
       "      <th>Quercus_x_Hispanica</th>\n",
       "      <th>Quercus_x_Turneri</th>\n",
       "      <th>Rhododendron_x_Russellianum</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3.433710e-28</td>\n",
       "      <td>5.348304e-13</td>\n",
       "      <td>3.802581e-22</td>\n",
       "      <td>3.766198e-09</td>\n",
       "      <td>7.841725e-20</td>\n",
       "      <td>1.972096e-24</td>\n",
       "      <td>2.519512e-10</td>\n",
       "      <td>2.995295e-17</td>\n",
       "      <td>9.449199e-14</td>\n",
       "      <td>9.545757e-24</td>\n",
       "      <td>1.446215e-11</td>\n",
       "      <td>1.345696e-14</td>\n",
       "      <td>6.928236e-05</td>\n",
       "      <td>3.902623e-10</td>\n",
       "      <td>4.263632e-10</td>\n",
       "      <td>2.873922e-22</td>\n",
       "      <td>6.923991e-21</td>\n",
       "      <td>3.188633e-17</td>\n",
       "      <td>1.838720e-19</td>\n",
       "      <td>4.546823e-15</td>\n",
       "      <td>5.138020e-10</td>\n",
       "      <td>2.224214e-12</td>\n",
       "      <td>1.648400e-12</td>\n",
       "      <td>5.458237e-12</td>\n",
       "      <td>4.731546e-12</td>\n",
       "      <td>2.300760e-20</td>\n",
       "      <td>2.594491e-14</td>\n",
       "      <td>7.926698e-25</td>\n",
       "      <td>2.528388e-14</td>\n",
       "      <td>4.327656e-12</td>\n",
       "      <td>7.784860e-08</td>\n",
       "      <td>4.411598e-12</td>\n",
       "      <td>2.487609e-21</td>\n",
       "      <td>1.704446e-13</td>\n",
       "      <td>1.366943e-14</td>\n",
       "      <td>9.598316e-21</td>\n",
       "      <td>7.031631e-14</td>\n",
       "      <td>3.743098e-15</td>\n",
       "      <td>2.874251e-14</td>\n",
       "      <td>1.068119e-10</td>\n",
       "      <td>1.497017e-11</td>\n",
       "      <td>1.433333e-14</td>\n",
       "      <td>8.025088e-19</td>\n",
       "      <td>1.113416e-12</td>\n",
       "      <td>4.200617e-16</td>\n",
       "      <td>5.081436e-13</td>\n",
       "      <td>4.907300e-09</td>\n",
       "      <td>2.151744e-16</td>\n",
       "      <td>1.083121e-15</td>\n",
       "      <td>4.163583e-19</td>\n",
       "      <td>4.123047e-13</td>\n",
       "      <td>9.999292e-01</td>\n",
       "      <td>1.847158e-13</td>\n",
       "      <td>2.104721e-18</td>\n",
       "      <td>3.689728e-12</td>\n",
       "      <td>4.427556e-08</td>\n",
       "      <td>1.136874e-23</td>\n",
       "      <td>3.840560e-13</td>\n",
       "      <td>2.876383e-19</td>\n",
       "      <td>3.065236e-19</td>\n",
       "      <td>1.551174e-11</td>\n",
       "      <td>6.251554e-23</td>\n",
       "      <td>1.901495e-09</td>\n",
       "      <td>1.535753e-16</td>\n",
       "      <td>2.549256e-20</td>\n",
       "      <td>2.148923e-15</td>\n",
       "      <td>2.114178e-16</td>\n",
       "      <td>4.105826e-11</td>\n",
       "      <td>1.161372e-16</td>\n",
       "      <td>2.117022e-20</td>\n",
       "      <td>3.544629e-20</td>\n",
       "      <td>8.732912e-26</td>\n",
       "      <td>6.023570e-20</td>\n",
       "      <td>3.975696e-10</td>\n",
       "      <td>3.350069e-10</td>\n",
       "      <td>3.302499e-14</td>\n",
       "      <td>6.316333e-20</td>\n",
       "      <td>2.001632e-13</td>\n",
       "      <td>3.653787e-20</td>\n",
       "      <td>2.000614e-12</td>\n",
       "      <td>5.466054e-22</td>\n",
       "      <td>1.730838e-21</td>\n",
       "      <td>4.984848e-19</td>\n",
       "      <td>2.032964e-09</td>\n",
       "      <td>1.328515e-10</td>\n",
       "      <td>3.371001e-19</td>\n",
       "      <td>1.789066e-15</td>\n",
       "      <td>6.142146e-18</td>\n",
       "      <td>4.422333e-11</td>\n",
       "      <td>1.977944e-23</td>\n",
       "      <td>5.756488e-19</td>\n",
       "      <td>1.269239e-06</td>\n",
       "      <td>8.044370e-18</td>\n",
       "      <td>1.523968e-27</td>\n",
       "      <td>1.961106e-17</td>\n",
       "      <td>4.147305e-18</td>\n",
       "      <td>1.253841e-07</td>\n",
       "      <td>2.656247e-17</td>\n",
       "      <td>1.259025e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2.101121e-18</td>\n",
       "      <td>2.999653e-05</td>\n",
       "      <td>2.260660e-13</td>\n",
       "      <td>9.393696e-15</td>\n",
       "      <td>1.082307e-07</td>\n",
       "      <td>4.048475e-13</td>\n",
       "      <td>3.776730e-11</td>\n",
       "      <td>5.494072e-11</td>\n",
       "      <td>7.775746e-07</td>\n",
       "      <td>2.167897e-10</td>\n",
       "      <td>4.649155e-29</td>\n",
       "      <td>4.717466e-12</td>\n",
       "      <td>1.897718e-12</td>\n",
       "      <td>1.181749e-06</td>\n",
       "      <td>1.429702e-09</td>\n",
       "      <td>2.058715e-13</td>\n",
       "      <td>4.837263e-17</td>\n",
       "      <td>2.123475e-09</td>\n",
       "      <td>4.438052e-20</td>\n",
       "      <td>3.423989e-13</td>\n",
       "      <td>2.780689e-18</td>\n",
       "      <td>2.516936e-21</td>\n",
       "      <td>7.192192e-20</td>\n",
       "      <td>4.171189e-18</td>\n",
       "      <td>2.040311e-17</td>\n",
       "      <td>2.191392e-23</td>\n",
       "      <td>2.845403e-06</td>\n",
       "      <td>3.936515e-22</td>\n",
       "      <td>4.128089e-12</td>\n",
       "      <td>2.614326e-09</td>\n",
       "      <td>8.065736e-18</td>\n",
       "      <td>3.142903e-14</td>\n",
       "      <td>2.261790e-13</td>\n",
       "      <td>6.499529e-15</td>\n",
       "      <td>3.964740e-15</td>\n",
       "      <td>2.275821e-15</td>\n",
       "      <td>4.691489e-27</td>\n",
       "      <td>3.266558e-24</td>\n",
       "      <td>1.561642e-17</td>\n",
       "      <td>1.450390e-16</td>\n",
       "      <td>1.573559e-14</td>\n",
       "      <td>1.415293e-04</td>\n",
       "      <td>1.445672e-09</td>\n",
       "      <td>5.077071e-10</td>\n",
       "      <td>5.038260e-22</td>\n",
       "      <td>5.086345e-04</td>\n",
       "      <td>2.088542e-08</td>\n",
       "      <td>1.752454e-04</td>\n",
       "      <td>4.474560e-08</td>\n",
       "      <td>8.526380e-07</td>\n",
       "      <td>1.726288e-08</td>\n",
       "      <td>1.497443e-13</td>\n",
       "      <td>3.909294e-11</td>\n",
       "      <td>5.301158e-01</td>\n",
       "      <td>2.001288e-01</td>\n",
       "      <td>2.468613e-12</td>\n",
       "      <td>4.396113e-05</td>\n",
       "      <td>1.511828e-11</td>\n",
       "      <td>1.996360e-14</td>\n",
       "      <td>2.457590e-13</td>\n",
       "      <td>4.944516e-11</td>\n",
       "      <td>2.432420e-14</td>\n",
       "      <td>2.329854e-14</td>\n",
       "      <td>1.599517e-02</td>\n",
       "      <td>9.718817e-19</td>\n",
       "      <td>7.356375e-13</td>\n",
       "      <td>7.282660e-10</td>\n",
       "      <td>1.073361e-17</td>\n",
       "      <td>1.447331e-08</td>\n",
       "      <td>3.083643e-06</td>\n",
       "      <td>3.329879e-10</td>\n",
       "      <td>8.605158e-15</td>\n",
       "      <td>1.588001e-11</td>\n",
       "      <td>1.615331e-17</td>\n",
       "      <td>5.923511e-08</td>\n",
       "      <td>2.872312e-12</td>\n",
       "      <td>3.421243e-12</td>\n",
       "      <td>6.277093e-12</td>\n",
       "      <td>1.040520e-10</td>\n",
       "      <td>6.493200e-18</td>\n",
       "      <td>8.215930e-10</td>\n",
       "      <td>6.979087e-07</td>\n",
       "      <td>1.771269e-11</td>\n",
       "      <td>5.086559e-14</td>\n",
       "      <td>1.352389e-09</td>\n",
       "      <td>2.735005e-11</td>\n",
       "      <td>2.528509e-01</td>\n",
       "      <td>1.165631e-10</td>\n",
       "      <td>5.468075e-10</td>\n",
       "      <td>1.531454e-07</td>\n",
       "      <td>6.265710e-14</td>\n",
       "      <td>1.608699e-13</td>\n",
       "      <td>7.947171e-11</td>\n",
       "      <td>3.353489e-16</td>\n",
       "      <td>2.671662e-27</td>\n",
       "      <td>2.000099e-14</td>\n",
       "      <td>2.098694e-18</td>\n",
       "      <td>3.524295e-23</td>\n",
       "      <td>6.273583e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2.921835e-16</td>\n",
       "      <td>9.932898e-01</td>\n",
       "      <td>8.595803e-11</td>\n",
       "      <td>4.194605e-07</td>\n",
       "      <td>7.902903e-08</td>\n",
       "      <td>8.810616e-14</td>\n",
       "      <td>1.967547e-04</td>\n",
       "      <td>2.673848e-08</td>\n",
       "      <td>3.716315e-06</td>\n",
       "      <td>1.023148e-09</td>\n",
       "      <td>8.609487e-26</td>\n",
       "      <td>1.396644e-12</td>\n",
       "      <td>6.769593e-16</td>\n",
       "      <td>2.316001e-06</td>\n",
       "      <td>1.228872e-08</td>\n",
       "      <td>4.194622e-16</td>\n",
       "      <td>7.918925e-16</td>\n",
       "      <td>9.822054e-07</td>\n",
       "      <td>7.321471e-21</td>\n",
       "      <td>9.005861e-16</td>\n",
       "      <td>1.024097e-16</td>\n",
       "      <td>6.922414e-16</td>\n",
       "      <td>3.079264e-16</td>\n",
       "      <td>8.132371e-14</td>\n",
       "      <td>2.527537e-17</td>\n",
       "      <td>2.301306e-23</td>\n",
       "      <td>1.715827e-04</td>\n",
       "      <td>4.768500e-28</td>\n",
       "      <td>5.134756e-15</td>\n",
       "      <td>1.391567e-13</td>\n",
       "      <td>2.961332e-17</td>\n",
       "      <td>1.078732e-12</td>\n",
       "      <td>1.188590e-15</td>\n",
       "      <td>2.358754e-19</td>\n",
       "      <td>1.702208e-21</td>\n",
       "      <td>1.106730e-08</td>\n",
       "      <td>1.767630e-07</td>\n",
       "      <td>2.677384e-23</td>\n",
       "      <td>3.168352e-19</td>\n",
       "      <td>2.030342e-19</td>\n",
       "      <td>2.185966e-25</td>\n",
       "      <td>3.619755e-10</td>\n",
       "      <td>1.616494e-07</td>\n",
       "      <td>8.670339e-16</td>\n",
       "      <td>3.243868e-13</td>\n",
       "      <td>8.070868e-07</td>\n",
       "      <td>2.547890e-06</td>\n",
       "      <td>4.651294e-12</td>\n",
       "      <td>2.111573e-14</td>\n",
       "      <td>2.473926e-17</td>\n",
       "      <td>7.470810e-06</td>\n",
       "      <td>1.920031e-12</td>\n",
       "      <td>1.927948e-15</td>\n",
       "      <td>1.021508e-12</td>\n",
       "      <td>5.441183e-03</td>\n",
       "      <td>2.969900e-07</td>\n",
       "      <td>2.952850e-07</td>\n",
       "      <td>3.914709e-18</td>\n",
       "      <td>7.606000e-17</td>\n",
       "      <td>3.225800e-15</td>\n",
       "      <td>2.395728e-09</td>\n",
       "      <td>2.497108e-10</td>\n",
       "      <td>3.554018e-21</td>\n",
       "      <td>1.662100e-05</td>\n",
       "      <td>8.940332e-19</td>\n",
       "      <td>6.351941e-12</td>\n",
       "      <td>3.103234e-11</td>\n",
       "      <td>2.452691e-16</td>\n",
       "      <td>6.276747e-10</td>\n",
       "      <td>2.656578e-09</td>\n",
       "      <td>2.733297e-11</td>\n",
       "      <td>7.423358e-07</td>\n",
       "      <td>2.740071e-16</td>\n",
       "      <td>2.444273e-18</td>\n",
       "      <td>1.709995e-13</td>\n",
       "      <td>5.150545e-05</td>\n",
       "      <td>1.731616e-08</td>\n",
       "      <td>3.903767e-16</td>\n",
       "      <td>1.026098e-11</td>\n",
       "      <td>1.995171e-18</td>\n",
       "      <td>9.167724e-11</td>\n",
       "      <td>7.277281e-06</td>\n",
       "      <td>6.257474e-11</td>\n",
       "      <td>1.612438e-11</td>\n",
       "      <td>3.262554e-12</td>\n",
       "      <td>8.052583e-04</td>\n",
       "      <td>2.164894e-08</td>\n",
       "      <td>7.968087e-13</td>\n",
       "      <td>2.495220e-12</td>\n",
       "      <td>2.751991e-13</td>\n",
       "      <td>5.233212e-12</td>\n",
       "      <td>2.902468e-19</td>\n",
       "      <td>1.392748e-10</td>\n",
       "      <td>5.084637e-17</td>\n",
       "      <td>1.307674e-14</td>\n",
       "      <td>1.953530e-11</td>\n",
       "      <td>5.075966e-20</td>\n",
       "      <td>1.478717e-29</td>\n",
       "      <td>6.578978e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1.308871e-32</td>\n",
       "      <td>1.977475e-11</td>\n",
       "      <td>3.351616e-23</td>\n",
       "      <td>2.230354e-20</td>\n",
       "      <td>3.502816e-16</td>\n",
       "      <td>6.294783e-25</td>\n",
       "      <td>2.902523e-20</td>\n",
       "      <td>6.400017e-16</td>\n",
       "      <td>1.926252e-14</td>\n",
       "      <td>7.881438e-24</td>\n",
       "      <td>4.887245e-15</td>\n",
       "      <td>1.920424e-09</td>\n",
       "      <td>9.439997e-12</td>\n",
       "      <td>2.299807e-23</td>\n",
       "      <td>1.347038e-11</td>\n",
       "      <td>4.167364e-25</td>\n",
       "      <td>4.283808e-15</td>\n",
       "      <td>4.833942e-21</td>\n",
       "      <td>5.341428e-21</td>\n",
       "      <td>9.998177e-01</td>\n",
       "      <td>6.293629e-18</td>\n",
       "      <td>5.775939e-23</td>\n",
       "      <td>1.713779e-15</td>\n",
       "      <td>1.390040e-28</td>\n",
       "      <td>9.048706e-16</td>\n",
       "      <td>5.877610e-21</td>\n",
       "      <td>1.207276e-15</td>\n",
       "      <td>4.605044e-18</td>\n",
       "      <td>1.298088e-22</td>\n",
       "      <td>2.713612e-22</td>\n",
       "      <td>2.573604e-19</td>\n",
       "      <td>1.744249e-16</td>\n",
       "      <td>1.232473e-16</td>\n",
       "      <td>3.301075e-09</td>\n",
       "      <td>1.939853e-18</td>\n",
       "      <td>1.229327e-24</td>\n",
       "      <td>4.852506e-15</td>\n",
       "      <td>5.025938e-25</td>\n",
       "      <td>2.693586e-20</td>\n",
       "      <td>1.670890e-14</td>\n",
       "      <td>3.549546e-15</td>\n",
       "      <td>1.033284e-15</td>\n",
       "      <td>3.880157e-19</td>\n",
       "      <td>7.129984e-18</td>\n",
       "      <td>8.055303e-31</td>\n",
       "      <td>9.466068e-12</td>\n",
       "      <td>6.483831e-18</td>\n",
       "      <td>3.052795e-05</td>\n",
       "      <td>2.405455e-09</td>\n",
       "      <td>5.503978e-24</td>\n",
       "      <td>2.821580e-15</td>\n",
       "      <td>4.497185e-18</td>\n",
       "      <td>3.065845e-09</td>\n",
       "      <td>7.378330e-15</td>\n",
       "      <td>2.555586e-14</td>\n",
       "      <td>6.081305e-10</td>\n",
       "      <td>1.579456e-17</td>\n",
       "      <td>9.047622e-19</td>\n",
       "      <td>2.367784e-11</td>\n",
       "      <td>1.075904e-25</td>\n",
       "      <td>4.498785e-16</td>\n",
       "      <td>5.848062e-15</td>\n",
       "      <td>5.271314e-19</td>\n",
       "      <td>3.728538e-11</td>\n",
       "      <td>1.270151e-16</td>\n",
       "      <td>3.924729e-11</td>\n",
       "      <td>9.232030e-17</td>\n",
       "      <td>1.993092e-21</td>\n",
       "      <td>8.908519e-24</td>\n",
       "      <td>9.727561e-17</td>\n",
       "      <td>1.159601e-15</td>\n",
       "      <td>3.470816e-22</td>\n",
       "      <td>3.970108e-21</td>\n",
       "      <td>2.079043e-23</td>\n",
       "      <td>1.515739e-04</td>\n",
       "      <td>9.886981e-22</td>\n",
       "      <td>2.658473e-11</td>\n",
       "      <td>2.948318e-11</td>\n",
       "      <td>2.943322e-19</td>\n",
       "      <td>7.808753e-15</td>\n",
       "      <td>9.223581e-17</td>\n",
       "      <td>5.466451e-20</td>\n",
       "      <td>3.689506e-24</td>\n",
       "      <td>2.500395e-20</td>\n",
       "      <td>1.585923e-07</td>\n",
       "      <td>7.076938e-15</td>\n",
       "      <td>1.717961e-16</td>\n",
       "      <td>2.602327e-16</td>\n",
       "      <td>5.330899e-15</td>\n",
       "      <td>5.913800e-20</td>\n",
       "      <td>2.106168e-22</td>\n",
       "      <td>1.049588e-12</td>\n",
       "      <td>1.096328e-13</td>\n",
       "      <td>2.004255e-20</td>\n",
       "      <td>3.392140e-27</td>\n",
       "      <td>3.559199e-16</td>\n",
       "      <td>7.504134e-15</td>\n",
       "      <td>3.150645e-14</td>\n",
       "      <td>8.039727e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.633677e-28</td>\n",
       "      <td>1.008424e-07</td>\n",
       "      <td>3.606601e-18</td>\n",
       "      <td>7.182548e-11</td>\n",
       "      <td>9.942548e-10</td>\n",
       "      <td>8.864652e-21</td>\n",
       "      <td>5.951617e-17</td>\n",
       "      <td>3.045933e-14</td>\n",
       "      <td>1.991672e-13</td>\n",
       "      <td>1.950652e-13</td>\n",
       "      <td>3.599673e-11</td>\n",
       "      <td>2.663026e-11</td>\n",
       "      <td>3.576236e-10</td>\n",
       "      <td>8.949008e-15</td>\n",
       "      <td>7.242122e-01</td>\n",
       "      <td>1.360760e-23</td>\n",
       "      <td>1.410882e-11</td>\n",
       "      <td>1.007786e-08</td>\n",
       "      <td>9.841323e-14</td>\n",
       "      <td>7.240196e-14</td>\n",
       "      <td>1.155021e-14</td>\n",
       "      <td>4.660305e-22</td>\n",
       "      <td>7.358877e-20</td>\n",
       "      <td>1.212077e-16</td>\n",
       "      <td>6.035013e-11</td>\n",
       "      <td>1.311413e-24</td>\n",
       "      <td>4.667759e-04</td>\n",
       "      <td>1.857283e-12</td>\n",
       "      <td>2.169474e-10</td>\n",
       "      <td>1.103575e-16</td>\n",
       "      <td>1.727881e-18</td>\n",
       "      <td>6.554913e-13</td>\n",
       "      <td>8.544757e-12</td>\n",
       "      <td>2.087905e-08</td>\n",
       "      <td>2.559144e-01</td>\n",
       "      <td>2.026646e-22</td>\n",
       "      <td>1.511882e-16</td>\n",
       "      <td>1.514927e-21</td>\n",
       "      <td>1.361797e-18</td>\n",
       "      <td>7.955576e-18</td>\n",
       "      <td>5.310623e-19</td>\n",
       "      <td>2.904103e-12</td>\n",
       "      <td>1.135499e-19</td>\n",
       "      <td>3.589276e-13</td>\n",
       "      <td>1.176284e-23</td>\n",
       "      <td>1.935375e-02</td>\n",
       "      <td>4.659270e-07</td>\n",
       "      <td>8.030665e-13</td>\n",
       "      <td>8.945575e-12</td>\n",
       "      <td>3.248935e-10</td>\n",
       "      <td>1.287004e-06</td>\n",
       "      <td>3.019493e-10</td>\n",
       "      <td>5.042573e-09</td>\n",
       "      <td>3.318832e-11</td>\n",
       "      <td>1.481235e-09</td>\n",
       "      <td>8.062551e-11</td>\n",
       "      <td>2.226014e-14</td>\n",
       "      <td>3.791770e-07</td>\n",
       "      <td>2.169669e-13</td>\n",
       "      <td>7.184216e-12</td>\n",
       "      <td>2.025718e-11</td>\n",
       "      <td>3.210854e-16</td>\n",
       "      <td>4.444289e-12</td>\n",
       "      <td>4.093861e-10</td>\n",
       "      <td>2.006223e-15</td>\n",
       "      <td>4.752891e-15</td>\n",
       "      <td>2.033064e-08</td>\n",
       "      <td>8.024678e-17</td>\n",
       "      <td>4.037086e-13</td>\n",
       "      <td>1.106557e-14</td>\n",
       "      <td>7.757542e-18</td>\n",
       "      <td>1.737055e-16</td>\n",
       "      <td>2.048937e-18</td>\n",
       "      <td>7.588706e-13</td>\n",
       "      <td>8.329841e-06</td>\n",
       "      <td>3.205451e-12</td>\n",
       "      <td>2.847871e-10</td>\n",
       "      <td>1.481115e-14</td>\n",
       "      <td>1.097482e-11</td>\n",
       "      <td>5.458133e-11</td>\n",
       "      <td>1.304944e-12</td>\n",
       "      <td>6.953440e-12</td>\n",
       "      <td>4.960879e-11</td>\n",
       "      <td>3.605270e-05</td>\n",
       "      <td>7.884579e-10</td>\n",
       "      <td>3.375861e-09</td>\n",
       "      <td>7.074864e-07</td>\n",
       "      <td>5.563842e-07</td>\n",
       "      <td>2.145965e-14</td>\n",
       "      <td>2.633207e-17</td>\n",
       "      <td>1.381673e-15</td>\n",
       "      <td>2.476902e-07</td>\n",
       "      <td>1.076768e-11</td>\n",
       "      <td>8.179821e-19</td>\n",
       "      <td>7.594950e-16</td>\n",
       "      <td>1.208844e-14</td>\n",
       "      <td>4.683861e-06</td>\n",
       "      <td>3.793102e-19</td>\n",
       "      <td>2.847067e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "0   4     3.433710e-28     5.348304e-13  3.802581e-22  3.766198e-09   \n",
       "1   7     2.101121e-18     2.999653e-05  2.260660e-13  9.393696e-15   \n",
       "2   9     2.921835e-16     9.932898e-01  8.595803e-11  4.194605e-07   \n",
       "3  12     1.308871e-32     1.977475e-11  3.351616e-23  2.230354e-20   \n",
       "4  13     1.633677e-28     1.008424e-07  3.606601e-18  7.182548e-11   \n",
       "\n",
       "   Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  Acer_Rufinerve  \\\n",
       "0   7.841725e-20  1.972096e-24     2.519512e-10  2.995295e-17    9.449199e-14   \n",
       "1   1.082307e-07  4.048475e-13     3.776730e-11  5.494072e-11    7.775746e-07   \n",
       "2   7.902903e-08  8.810616e-14     1.967547e-04  2.673848e-08    3.716315e-06   \n",
       "3   3.502816e-16  6.294783e-25     2.902523e-20  6.400017e-16    1.926252e-14   \n",
       "4   9.942548e-10  8.864652e-21     5.951617e-17  3.045933e-14    1.991672e-13   \n",
       "\n",
       "   Acer_Saccharinum  Alnus_Cordata  Alnus_Maximowiczii   Alnus_Rubra  \\\n",
       "0      9.545757e-24   1.446215e-11        1.345696e-14  6.928236e-05   \n",
       "1      2.167897e-10   4.649155e-29        4.717466e-12  1.897718e-12   \n",
       "2      1.023148e-09   8.609487e-26        1.396644e-12  6.769593e-16   \n",
       "3      7.881438e-24   4.887245e-15        1.920424e-09  9.439997e-12   \n",
       "4      1.950652e-13   3.599673e-11        2.663026e-11  3.576236e-10   \n",
       "\n",
       "   Alnus_Sieboldiana  Alnus_Viridis  Arundinaria_Simonii  \\\n",
       "0       3.902623e-10   4.263632e-10         2.873922e-22   \n",
       "1       1.181749e-06   1.429702e-09         2.058715e-13   \n",
       "2       2.316001e-06   1.228872e-08         4.194622e-16   \n",
       "3       2.299807e-23   1.347038e-11         4.167364e-25   \n",
       "4       8.949008e-15   7.242122e-01         1.360760e-23   \n",
       "\n",
       "   Betula_Austrosinensis  Betula_Pendula  Callicarpa_Bodinieri  \\\n",
       "0           6.923991e-21    3.188633e-17          1.838720e-19   \n",
       "1           4.837263e-17    2.123475e-09          4.438052e-20   \n",
       "2           7.918925e-16    9.822054e-07          7.321471e-21   \n",
       "3           4.283808e-15    4.833942e-21          5.341428e-21   \n",
       "4           1.410882e-11    1.007786e-08          9.841323e-14   \n",
       "\n",
       "   Castanea_Sativa  Celtis_Koraiensis  Cercis_Siliquastrum  Cornus_Chinensis  \\\n",
       "0     4.546823e-15       5.138020e-10         2.224214e-12      1.648400e-12   \n",
       "1     3.423989e-13       2.780689e-18         2.516936e-21      7.192192e-20   \n",
       "2     9.005861e-16       1.024097e-16         6.922414e-16      3.079264e-16   \n",
       "3     9.998177e-01       6.293629e-18         5.775939e-23      1.713779e-15   \n",
       "4     7.240196e-14       1.155021e-14         4.660305e-22      7.358877e-20   \n",
       "\n",
       "   Cornus_Controversa  Cornus_Macrophylla  Cotinus_Coggygria  \\\n",
       "0        5.458237e-12        4.731546e-12       2.300760e-20   \n",
       "1        4.171189e-18        2.040311e-17       2.191392e-23   \n",
       "2        8.132371e-14        2.527537e-17       2.301306e-23   \n",
       "3        1.390040e-28        9.048706e-16       5.877610e-21   \n",
       "4        1.212077e-16        6.035013e-11       1.311413e-24   \n",
       "\n",
       "   Crataegus_Monogyna  Cytisus_Battandieri  Eucalyptus_Glaucescens  \\\n",
       "0        2.594491e-14         7.926698e-25            2.528388e-14   \n",
       "1        2.845403e-06         3.936515e-22            4.128089e-12   \n",
       "2        1.715827e-04         4.768500e-28            5.134756e-15   \n",
       "3        1.207276e-15         4.605044e-18            1.298088e-22   \n",
       "4        4.667759e-04         1.857283e-12            2.169474e-10   \n",
       "\n",
       "   Eucalyptus_Neglecta  Eucalyptus_Urnigera  Fagus_Sylvatica  Ginkgo_Biloba  \\\n",
       "0         4.327656e-12         7.784860e-08     4.411598e-12   2.487609e-21   \n",
       "1         2.614326e-09         8.065736e-18     3.142903e-14   2.261790e-13   \n",
       "2         1.391567e-13         2.961332e-17     1.078732e-12   1.188590e-15   \n",
       "3         2.713612e-22         2.573604e-19     1.744249e-16   1.232473e-16   \n",
       "4         1.103575e-16         1.727881e-18     6.554913e-13   8.544757e-12   \n",
       "\n",
       "   Ilex_Aquifolium  Ilex_Cornuta  Liquidambar_Styraciflua  \\\n",
       "0     1.704446e-13  1.366943e-14             9.598316e-21   \n",
       "1     6.499529e-15  3.964740e-15             2.275821e-15   \n",
       "2     2.358754e-19  1.702208e-21             1.106730e-08   \n",
       "3     3.301075e-09  1.939853e-18             1.229327e-24   \n",
       "4     2.087905e-08  2.559144e-01             2.026646e-22   \n",
       "\n",
       "   Liriodendron_Tulipifera  Lithocarpus_Cleistocarpus  Lithocarpus_Edulis  \\\n",
       "0             7.031631e-14               3.743098e-15        2.874251e-14   \n",
       "1             4.691489e-27               3.266558e-24        1.561642e-17   \n",
       "2             1.767630e-07               2.677384e-23        3.168352e-19   \n",
       "3             4.852506e-15               5.025938e-25        2.693586e-20   \n",
       "4             1.511882e-16               1.514927e-21        1.361797e-18   \n",
       "\n",
       "   Magnolia_Heptapeta  Magnolia_Salicifolia   Morus_Nigra  Olea_Europaea  \\\n",
       "0        1.068119e-10          1.497017e-11  1.433333e-14   8.025088e-19   \n",
       "1        1.450390e-16          1.573559e-14  1.415293e-04   1.445672e-09   \n",
       "2        2.030342e-19          2.185966e-25  3.619755e-10   1.616494e-07   \n",
       "3        1.670890e-14          3.549546e-15  1.033284e-15   3.880157e-19   \n",
       "4        7.955576e-18          5.310623e-19  2.904103e-12   1.135499e-19   \n",
       "\n",
       "    Phildelphus  Populus_Adenopoda  Populus_Grandidentata  Populus_Nigra  \\\n",
       "0  1.113416e-12       4.200617e-16           5.081436e-13   4.907300e-09   \n",
       "1  5.077071e-10       5.038260e-22           5.086345e-04   2.088542e-08   \n",
       "2  8.670339e-16       3.243868e-13           8.070868e-07   2.547890e-06   \n",
       "3  7.129984e-18       8.055303e-31           9.466068e-12   6.483831e-18   \n",
       "4  3.589276e-13       1.176284e-23           1.935375e-02   4.659270e-07   \n",
       "\n",
       "   Prunus_Avium  Prunus_X_Shmittii  Pterocarya_Stenoptera  Quercus_Afares  \\\n",
       "0  2.151744e-16       1.083121e-15           4.163583e-19    4.123047e-13   \n",
       "1  1.752454e-04       4.474560e-08           8.526380e-07    1.726288e-08   \n",
       "2  4.651294e-12       2.111573e-14           2.473926e-17    7.470810e-06   \n",
       "3  3.052795e-05       2.405455e-09           5.503978e-24    2.821580e-15   \n",
       "4  8.030665e-13       8.945575e-12           3.248935e-10    1.287004e-06   \n",
       "\n",
       "   Quercus_Agrifolia  Quercus_Alnifolia  Quercus_Brantii  Quercus_Canariensis  \\\n",
       "0       9.999292e-01       1.847158e-13     2.104721e-18         3.689728e-12   \n",
       "1       1.497443e-13       3.909294e-11     5.301158e-01         2.001288e-01   \n",
       "2       1.920031e-12       1.927948e-15     1.021508e-12         5.441183e-03   \n",
       "3       4.497185e-18       3.065845e-09     7.378330e-15         2.555586e-14   \n",
       "4       3.019493e-10       5.042573e-09     3.318832e-11         1.481235e-09   \n",
       "\n",
       "   Quercus_Castaneifolia  Quercus_Cerris  Quercus_Chrysolepis  \\\n",
       "0           4.427556e-08    1.136874e-23         3.840560e-13   \n",
       "1           2.468613e-12    4.396113e-05         1.511828e-11   \n",
       "2           2.969900e-07    2.952850e-07         3.914709e-18   \n",
       "3           6.081305e-10    1.579456e-17         9.047622e-19   \n",
       "4           8.062551e-11    2.226014e-14         3.791770e-07   \n",
       "\n",
       "   Quercus_Coccifera  Quercus_Coccinea  Quercus_Crassifolia  \\\n",
       "0       2.876383e-19      3.065236e-19         1.551174e-11   \n",
       "1       1.996360e-14      2.457590e-13         4.944516e-11   \n",
       "2       7.606000e-17      3.225800e-15         2.395728e-09   \n",
       "3       2.367784e-11      1.075904e-25         4.498785e-16   \n",
       "4       2.169669e-13      7.184216e-12         2.025718e-11   \n",
       "\n",
       "   Quercus_Crassipes  Quercus_Dolicholepis  Quercus_Ellipsoidalis  \\\n",
       "0       6.251554e-23          1.901495e-09           1.535753e-16   \n",
       "1       2.432420e-14          2.329854e-14           1.599517e-02   \n",
       "2       2.497108e-10          3.554018e-21           1.662100e-05   \n",
       "3       5.848062e-15          5.271314e-19           3.728538e-11   \n",
       "4       3.210854e-16          4.444289e-12           4.093861e-10   \n",
       "\n",
       "   Quercus_Greggii  Quercus_Hartwissiana  Quercus_Ilex  Quercus_Imbricaria  \\\n",
       "0     2.549256e-20          2.148923e-15  2.114178e-16        4.105826e-11   \n",
       "1     9.718817e-19          7.356375e-13  7.282660e-10        1.073361e-17   \n",
       "2     8.940332e-19          6.351941e-12  3.103234e-11        2.452691e-16   \n",
       "3     1.270151e-16          3.924729e-11  9.232030e-17        1.993092e-21   \n",
       "4     2.006223e-15          4.752891e-15  2.033064e-08        8.024678e-17   \n",
       "\n",
       "   Quercus_Infectoria_sub  Quercus_Kewensis  Quercus_Nigra  Quercus_Palustris  \\\n",
       "0            1.161372e-16      2.117022e-20   3.544629e-20       8.732912e-26   \n",
       "1            1.447331e-08      3.083643e-06   3.329879e-10       8.605158e-15   \n",
       "2            6.276747e-10      2.656578e-09   2.733297e-11       7.423358e-07   \n",
       "3            8.908519e-24      9.727561e-17   1.159601e-15       3.470816e-22   \n",
       "4            4.037086e-13      1.106557e-14   7.757542e-18       1.737055e-16   \n",
       "\n",
       "   Quercus_Phellos  Quercus_Phillyraeoides  Quercus_Pontica  \\\n",
       "0     6.023570e-20            3.975696e-10     3.350069e-10   \n",
       "1     1.588001e-11            1.615331e-17     5.923511e-08   \n",
       "2     2.740071e-16            2.444273e-18     1.709995e-13   \n",
       "3     3.970108e-21            2.079043e-23     1.515739e-04   \n",
       "4     2.048937e-18            7.588706e-13     8.329841e-06   \n",
       "\n",
       "   Quercus_Pubescens  Quercus_Pyrenaica  Quercus_Rhysophylla  Quercus_Rubra  \\\n",
       "0       3.302499e-14       6.316333e-20         2.001632e-13   3.653787e-20   \n",
       "1       2.872312e-12       3.421243e-12         6.277093e-12   1.040520e-10   \n",
       "2       5.150545e-05       1.731616e-08         3.903767e-16   1.026098e-11   \n",
       "3       9.886981e-22       2.658473e-11         2.948318e-11   2.943322e-19   \n",
       "4       3.205451e-12       2.847871e-10         1.481115e-14   1.097482e-11   \n",
       "\n",
       "   Quercus_Semecarpifolia  Quercus_Shumardii  Quercus_Suber  Quercus_Texana  \\\n",
       "0            2.000614e-12       5.466054e-22   1.730838e-21    4.984848e-19   \n",
       "1            6.493200e-18       8.215930e-10   6.979087e-07    1.771269e-11   \n",
       "2            1.995171e-18       9.167724e-11   7.277281e-06    6.257474e-11   \n",
       "3            7.808753e-15       9.223581e-17   5.466451e-20    3.689506e-24   \n",
       "4            5.458133e-11       1.304944e-12   6.953440e-12    4.960879e-11   \n",
       "\n",
       "   Quercus_Trojana  Quercus_Variabilis  Quercus_Vulcanica  \\\n",
       "0     2.032964e-09        1.328515e-10       3.371001e-19   \n",
       "1     5.086559e-14        1.352389e-09       2.735005e-11   \n",
       "2     1.612438e-11        3.262554e-12       8.052583e-04   \n",
       "3     2.500395e-20        1.585923e-07       7.076938e-15   \n",
       "4     3.605270e-05        7.884579e-10       3.375861e-09   \n",
       "\n",
       "   Quercus_x_Hispanica  Quercus_x_Turneri  Rhododendron_x_Russellianum  \\\n",
       "0         1.789066e-15       6.142146e-18                 4.422333e-11   \n",
       "1         2.528509e-01       1.165631e-10                 5.468075e-10   \n",
       "2         2.164894e-08       7.968087e-13                 2.495220e-12   \n",
       "3         1.717961e-16       2.602327e-16                 5.330899e-15   \n",
       "4         7.074864e-07       5.563842e-07                 2.145965e-14   \n",
       "\n",
       "   Salix_Fragilis  Salix_Intergra   Sorbus_Aria  Tilia_Oliveri  \\\n",
       "0    1.977944e-23    5.756488e-19  1.269239e-06   8.044370e-18   \n",
       "1    1.531454e-07    6.265710e-14  1.608699e-13   7.947171e-11   \n",
       "2    2.751991e-13    5.233212e-12  2.902468e-19   1.392748e-10   \n",
       "3    5.913800e-20    2.106168e-22  1.049588e-12   1.096328e-13   \n",
       "4    2.633207e-17    1.381673e-15  2.476902e-07   1.076768e-11   \n",
       "\n",
       "   Tilia_Platyphyllos  Tilia_Tomentosa  Ulmus_Bergmanniana  Viburnum_Tinus  \\\n",
       "0        1.523968e-27     1.961106e-17        4.147305e-18    1.253841e-07   \n",
       "1        3.353489e-16     2.671662e-27        2.000099e-14    2.098694e-18   \n",
       "2        5.084637e-17     1.307674e-14        1.953530e-11    5.075966e-20   \n",
       "3        2.004255e-20     3.392140e-27        3.559199e-16    7.504134e-15   \n",
       "4        8.179821e-19     7.594950e-16        1.208844e-14    4.683861e-06   \n",
       "\n",
       "   Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "0                  2.656247e-17     1.259025e-14  \n",
       "1                  3.524295e-23     6.273583e-09  \n",
       "2                  1.478717e-29     6.578978e-10  \n",
       "3                  3.150645e-14     8.039727e-19  \n",
       "4                  3.793102e-19     2.847067e-17  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97a04843-bc12-413a-86a9-3b488e9ee49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Quercus_Agrifolia\n"
     ]
    }
   ],
   "source": [
    "probabilities = submission_df.iloc[0, 1:]  # Exclude the image_id column\n",
    "\n",
    "# Find the index of the maximum probability\n",
    "predicted_index = probabilities.idxmax()\n",
    "\n",
    "# Display the predicted class\n",
    "print(f\"Predicted class: {predicted_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea6440d-d6d0-4ba4-80e9-b346596cb3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999292"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.999292e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f7fe6c7-15be-40a0-86a2-996e6825bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3af8ff-3469-4aed-9f4d-c006ad3dba23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce3653-d617-4118-bd91-afe85631bf54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
